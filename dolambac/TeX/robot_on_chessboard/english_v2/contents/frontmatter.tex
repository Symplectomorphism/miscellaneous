\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%            addressline={}, 
%%            city={},
%%            postcode={}, 
%%            state={},
%%            country={}}
%% \fntext[label3]{}

\title{Mischievous Sibling's Grid World}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author[label1]{Aykut C. Satici}
\ead{aykutsatici@boisestate.edu}

% \author[label2]{Gokhan Atinc}
% \ead{gokhan.atinc@mathworks.com}

%Department and Organization
\affiliation[label1]{organization={Boise State University},
            addressline={Mechanical and Biomedical Engineering}, 
            city={Boise},
            postcode={83725}, 
            state={Idaho},
            country={USA}}

\cortext[cor1]{Corresponding author}

% \affiliation[label2]{organization={Mathworks Inc.},
%             addressline={1 Lakeside Campus Drive}, 
%             city={Natick},
%             postcode={01760}, 
%             state={Massachusetts},
%             country={USA}}

\begin{abstract}
    % This is a technical note solving an interesting question posed by a friend
    % and colleague, G\"{o}khan At{\i}n\c{c}. 
    This is a technical note that introduces a novel grid world environment and
    an optimal control problem that is meant to be solved by a reinforcement
    learning (RL) agent in one-shot. That is to say, the algorithm that the RL
    agent runs is supposed to be able to solve the environment by training only
    for a single episode. The environment is very similar to the well-known Grid
    World problem, but with a twist. We solve the problem in two different ways:
    first using a direct probability calculation and then using reinforcement
    learning on a judiciously designed Markov Decision Process. The results are
    compared and discussed. The numerical solution to the problem allows us to 
    provide further statistics that sheds some more insight into the problem.
\end{abstract}

% %%Graphical abstract
% \begin{graphicalabstract}
% %\includegraphics{grabs}
% \end{graphicalabstract}
% 
% 
% %%Research highlights
% \begin{highlights}
% \item Research highlight 1
% \item Research highlight 2
% \end{highlights}


\begin{keyword}
Probability \sep Expectations \sep Reinforcement learning \sep Gymnasium \sep
Policy iteration 

% \JEL C45 \sep C53 \sep C55 \sep C82 \sep F47 \sep O50
%% keywords here, in the form: keyword \sep keyword
%% PACS codes here, in the form: \PACS code \sep code
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}


\end{frontmatter}