{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import gymnasium as gym\n",
    "from gridworld.envs import SiblingGridWorldEnv\n",
    "from gymnasium.envs.registration import register\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from tabulate import tabulate\n",
    "import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "SEEDS = (12, 34, 56, 78, 90)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import *\n",
    "from sibling_gw_agent import SiblingGWAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "params = {\n",
    "    'figure.figsize': (15, 8),\n",
    "    'font.size': 24,\n",
    "    'legend.fontsize': 20,\n",
    "    'axes.titlesize': 28,\n",
    "    'axes.labelsize': 24,\n",
    "    'xtick.labelsize': 20,\n",
    "    'ytick.labelsize': 20\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "layout = {\n",
    "    \"Training\": {\n",
    "        \"Q_gw\": [\"Multiline\", [\"Q_gw/center\", \"Q_gw/corner\"]],\n",
    "        \"Q_bandit\": [\"Multiline\", [\"Q_bandit/zero\", \"Q_bandit/twenty\", \"Q_bandit/correct\"]],\n",
    "    },\n",
    "}\n",
    "\n",
    "writer = SummaryWriter('runs/sibling_gw', comment=\"Sibling_GW\")\n",
    "writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def sibling():\n",
    "    env = SiblingGridWorldEnv(P_gridworld)\n",
    "    env = TimeLimit(env, max_episode_steps=100)\n",
    "#     env = RelativePositionenv)\n",
    "    return env\n",
    "\n",
    "register(\n",
    "    id='SiblingGridWorld-v0',\n",
    "    entry_point=sibling,\n",
    "    max_episode_steps=100,\n",
    ")\n",
    "\n",
    "env = gym.make('SiblingGridWorld-v0')\n",
    "env = env.unwrapped\n",
    " #env.render_mode = 'human'\n",
    "obs, info = env.reset(options={'randomize_world': True})\n",
    "print(env._true_world_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1\n",
    "agent = SiblingGWAgent(env, gamma=1.0, \n",
    "            init_alpha=0.5, min_alpha=0.05, alpha_decay_ratio=0.5, \n",
    "            init_epsilon=1.0, min_epsilon=0.1, epsilon_decay_ratio=0.9, \n",
    "            n_episodes=n_episodes)\n",
    "# agent = SiblingGWAgent(env, min_epsilon=0.5, epsilon_decay_ratio=0.9, n_episodes=n_episodes)\n",
    "# agent.episode = 5000\n",
    "# agent.epsilons[agent.episode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 382.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(agent.episode, agent.episode + n_episodes)):\n",
    "    agent.episode = episode\n",
    "    state, info = env.reset()\n",
    "    # if episode % 3_500 == 0:\n",
    "    #     state, info = env.reset(options={'randomize_world': True})\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        #action = agent.select_action(state)\n",
    "        action = agent.custom_action(state)[1]\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        # update the agent\n",
    "        agent.update(state, action, reward, terminated, next_state)\n",
    "\n",
    "        # update if the environment is done or truncated\n",
    "        done = terminated or truncated\n",
    "        state = next_state\n",
    "        # time.sleep(1)\n",
    "\n",
    "    if episode % 1 == 0:\n",
    "        writer.add_scalar(\"Q_gw/center\",\n",
    "            np.max(agent.Q_gw[agent.state_multi_to_lin(np.array([2, 2]))]), \n",
    "            episode\n",
    "        )\n",
    "        writer.add_scalar(\"Q_gw/corner\",\n",
    "            np.max(agent.Q_gw[agent.state_multi_to_lin(np.array([0, 0]))]), \n",
    "            episode\n",
    "        )\n",
    "        writer.add_scalar(\"Q_bandit/zero\",\n",
    "            np.max(agent.Q_bandit[0]), \n",
    "            episode\n",
    "        )\n",
    "        writer.add_scalar(\"Q_bandit/twenty\",\n",
    "            np.max(agent.Q_bandit[20]), \n",
    "            episode\n",
    "        )\n",
    "        writer.add_scalar(\"Q_bandit/correct\",\n",
    "            np.max(agent.Q_bandit[env._true_world_idx]), \n",
    "            episode\n",
    "        )\n",
    "        # writer.add_image(\"Q_gw\", \n",
    "        #     -agent.Q_gw/np.max(np.abs(agent.Q_gw)), episode, dataformats='HW')\n",
    "\n",
    "# time.sleep(2)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "\n",
    "env.close()\n",
    "print(env.num_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.  , -0.5 , -1.  , -0.5 , -1.  , -1.  , -0.4 ,  0.  , -1.  ,\n",
       "        0.  , -1.  ,  0.  , -0.4 ,  0.  , -1.  ,  0.  , -1.  ,  0.  ,\n",
       "       -0.25, -0.25, -1.  , -1.  , -1.  , -1.  ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q_bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices = np.where(agent.Q_bandit == np.max(agent.Q_bandit))[0]\n",
    "max_indices[np.where(np.where(agent.Q_bandit == np.max(agent.Q_bandit))[0] == env._true_world_idx)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "env.render_mode = None\n",
    "# obs, info = env.reset(options={'randomize_world': True})\n",
    "obs, _ = env.reset()\n",
    "env._agent_location = np.array([2, 2])\n",
    "obs = env._agent_location\n",
    "\n",
    "avg_steps = 100\n",
    "alpha = 0.1\n",
    "running_avg = [10]\n",
    "max_ep_len = 20\n",
    "for e in tqdm(range(1, 1_000)):\n",
    "    for i in range(1, max_ep_len):\n",
    "        # action = agent.greedy_action(obs)\n",
    "        action = agent.custom_action(obs)[1]\n",
    "        obs, rew, done, trunc, info = env.step(action)\n",
    "        # print(obs, rew, info)\n",
    "        # time.sleep(0.05)\n",
    "        if done or i == max_ep_len - 1:\n",
    "            # print(f\"Finished in {i} steps.\")\n",
    "            avg_steps += 1/e * (i - avg_steps)\n",
    "            running_avg += [(1-alpha) * running_avg[-1] + alpha * avg_steps]\n",
    "            break\n",
    "    obs, _ = env.reset()\n",
    "    env._agent_location = np.array([2, 2])\n",
    "    obs = env._agent_location\n",
    "    # if e % 100 == 0:\n",
    "    #     print(f\"Episode {e} finished, current average estimate is {avg_steps}.\")\n",
    "\n",
    "print(f\"Cumulative average estimate: {avg_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(running_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.render_mode = 'human'\n",
    "obs, info = env.reset()\n",
    "env._agent_location = np.array([2, 2])\n",
    "obs = env._agent_location\n",
    "# print(np.concatenate([env._agent_location, env._world_belief]))\n",
    "env._render_frame()\n",
    "# time.sleep(1.0)\n",
    "print(env._true_world_idx)\n",
    "\n",
    "for i in range(1,max_ep_len+1):\n",
    "    action = agent.greedy_action(obs)\n",
    "    obs, rew, done, trunc, info = env.step(action)\n",
    "    # print(obs, rew, info)\n",
    "    # time.sleep(0.05)\n",
    "    if done or trunc:\n",
    "        print(f\"Finished in {i} steps.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(agent.Q_bandit), np.argmax(agent.Q_bandit), env._true_world_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.Q_bandit)\n",
    "print(agent.N_bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
